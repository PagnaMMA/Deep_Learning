{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEEP LEARNING\n",
    "# ===============================================================\n",
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Layer Perceptron in Sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "1. Understand **Feature Scaling** and its importance in Deep learning.\n",
    "2. Learn **Model Selection** strategies for tuning an MLP model.\n",
    "3. Implement an MLP classifier using **Scikit-Learn**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Breast Cancer dataset\n",
    "cancer_data = load_breast_cancer()\n",
    "X, y = cancer_data.data, cancer_data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features by removing the mean and scaling to unit variance\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Scaling Analysis\n",
    "\n",
    "### Why is Feature Scaling Important?\n",
    "Feature scaling ensures that all features contribute equally to the learning process. Neural networks are sensitive to feature magnitudes, and unscaled data can lead to:\n",
    "- **Slower convergence**: Large feature values cause large weight updates, making training unstable.\n",
    "- **Suboptimal performance**: Some features may dominate others due to larger numerical values.\n",
    "- **Gradient vanishing or explosion**: Preventing the network from learning effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an MLPClassifier model\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(64, 32),max_iter=1000, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection Analysis\n",
    "\n",
    "### Key Hyperparameters:\n",
    "1. **hidden_layer_sizes**: Determines the number and size of hidden layers (e.g., `(10, 5)` means two layers with 10 and 5 neurons).\n",
    "2. **max_iter**: Number of iterations for training (higher values improve convergence).\n",
    "3. **activation**: Activation function (`relu`, `logistic`, `tanh`, etc.).\n",
    "4. **solver**: Optimization algorithm (`adam`, `sgd`, `lbfgs`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "# Train the model on the training data\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96        43\n",
      "           1       0.97      0.99      0.98        71\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate a classification report\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\\n\", class_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remarks, Comments, and Questions\n",
    "\n",
    "### Observations:\n",
    "1. **Feature Scaling Improves Performance**: The model performed significantly worse without feature scaling.\n",
    "2. **Model Selection Matters**: Increasing the number of hidden layers improved accuracy slightly.\n",
    "3. **Computational Cost**: More layers and neurons increased training time.\n",
    "\n",
    "### Questions:\n",
    "1. How can we determine the optimal number of hidden layers?\n",
    "2. How does the choice of activation functions impact performance?\n",
    "3. What other techniques (e.g., dropout, batch normalization) could further improve the model?\n",
    "\n",
    "### Next Steps:\n",
    "- Experiment with different activation functions (`relu`, `tanh`).\n",
    "- Try different solvers (`adam`, `sgd`).\n",
    "- Implement a **grid search** for hyperparameter tuning.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
